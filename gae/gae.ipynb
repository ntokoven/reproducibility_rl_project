{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://datascience.stackexchange.com/questions/32480/how-does-generalised-advantage-estimation-work\n",
    "https://lilianweng.github.io/lil-log/2018/02/19/a-long-peek-into-reinforcement-learning.html#combining-td-and-mc-learning\n",
    "https://arxiv.org/pdf/1506.02438.pdf\n",
    "https://github.com/higgsfield/RL-Adventure-2\n",
    "http://www.breloff.com/DeepRL-OnlineGAE/\n",
    "https://arxiv.org/pdf/1804.02717.pdf\n",
    "https://ewrl.files.wordpress.com/2015/02/ewrl12_2015_submission_18.pdf\n",
    "https://github.com/Kaixhin/Dist-A3C\n",
    "https://github.com/Kaixhin/Dist-A3C/blob/master/client.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.distributions as distributions\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import numpy as np\n",
    "import gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('MountainCar-v0')\n",
    "\n",
    "assert isinstance(env.observation_space, gym.spaces.Box)\n",
    "assert isinstance(env.action_space, gym.spaces.Discrete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1234\n",
    "\n",
    "env.seed(SEED);\n",
    "np.random.seed(SEED);\n",
    "torch.manual_seed(SEED);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, dropout = 0.25):\n",
    "        super().__init__()\n",
    "\n",
    "        self.fc_1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc_2 = nn.Linear(hidden_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fc_1(x)\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc_2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = env.observation_space.shape[0]\n",
    "HIDDEN_DIM = 128\n",
    "OUTPUT_DIM = env.action_space.n\n",
    "\n",
    "actor = MLP(INPUT_DIM, HIDDEN_DIM, OUTPUT_DIM)\n",
    "critic = MLP(INPUT_DIM, HIDDEN_DIM, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (fc_1): Linear(in_features=2, out_features=128, bias=True)\n",
       "  (fc_2): Linear(in_features=128, out_features=1, bias=True)\n",
       "  (dropout): Dropout(p=0.25, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        torch.nn.init.xavier_normal_(m.weight)\n",
    "        m.bias.data.fill_(0)\n",
    "        \n",
    "actor.apply(init_weights)\n",
    "critic.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 0.01\n",
    "\n",
    "actor_optimizer = optim.Adam(actor.parameters(), lr = LEARNING_RATE)\n",
    "critic_optimizer = optim.Adam(critic.parameters(), lr = LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(env, actor, critic, actor_optimizer, critic_optimizer, discount_factor, trace_decay):\n",
    "    \n",
    "    log_prob_actions = []\n",
    "    values = []\n",
    "    rewards = []\n",
    "    done = False\n",
    "    episode_reward = 0\n",
    "\n",
    "    state = env.reset()\n",
    "\n",
    "    while not done:\n",
    "\n",
    "        state = torch.FloatTensor(state).unsqueeze(0)\n",
    "\n",
    "        action_preds = actor(state)\n",
    "        value_pred = critic(state)\n",
    "                \n",
    "        action_probs = F.softmax(action_preds, dim = -1)\n",
    "                \n",
    "        dist = distributions.Categorical(action_probs)\n",
    "\n",
    "        action = dist.sample()\n",
    "        \n",
    "        log_prob_action = dist.log_prob(action)\n",
    "        \n",
    "        state, reward, done, _ = env.step(action.item())\n",
    "\n",
    "        log_prob_actions.append(log_prob_action)\n",
    "        values.append(value_pred)\n",
    "        rewards.append(reward)\n",
    "\n",
    "        episode_reward += reward\n",
    "    \n",
    "    log_prob_actions = torch.cat(log_prob_actions)\n",
    "    values = torch.cat(values).squeeze(-1)\n",
    "    \n",
    "    returns = calculate_returns(rewards, discount_factor)\n",
    "    advantages = calculate_advantages(rewards, values, discount_factor, trace_decay)\n",
    "    \n",
    "    policy_loss, value_loss = update_policy(advantages, log_prob_actions, returns, values, actor_optimizer, critic_optimizer)\n",
    "\n",
    "    return policy_loss, value_loss, episode_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_returns(rewards, discount_factor, normalize = True):\n",
    "    \n",
    "    returns = []\n",
    "    R = 0\n",
    "    \n",
    "    for r in reversed(rewards):\n",
    "        R = r + R * discount_factor\n",
    "        returns.insert(0, R)\n",
    "        \n",
    "    returns = torch.tensor(returns)\n",
    "    \n",
    "    if normalize:\n",
    "        \n",
    "        returns = (returns - returns.mean()) / returns.std()\n",
    "        \n",
    "    return returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_advantages(rewards, values, discount_factor, trace_decay, normalize = True):\n",
    "    \n",
    "    advantages = []\n",
    "    advantage = 0\n",
    "    next_value = 0\n",
    "    \n",
    "    for r, v in zip(reversed(rewards), reversed(values)):\n",
    "        td_error = r + next_value * discount_factor - v\n",
    "        advantage = td_error + advantage * discount_factor * trace_decay\n",
    "        next_value = v\n",
    "        advantages.insert(0, advantage)\n",
    "        \n",
    "    advantages = torch.tensor(advantages)\n",
    "    \n",
    "    if normalize:\n",
    "        advantages = (advantages - advantages.mean()) / advantages.std()\n",
    "        \n",
    "    return advantages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_policy(advantages, log_prob_actions, returns, values, actor_optimizer, critic_optimizer):\n",
    "        \n",
    "    advantages = advantages.detach()\n",
    "    returns = returns.detach()\n",
    "        \n",
    "    policy_loss = - (advantages * log_prob_actions).mean()\n",
    "    \n",
    "    value_loss = F.smooth_l1_loss(returns, values).mean()\n",
    "        \n",
    "    actor_optimizer.zero_grad()\n",
    "    critic_optimizer.zero_grad()\n",
    "    \n",
    "    policy_loss.backward()\n",
    "    value_loss.backward()\n",
    "    \n",
    "    actor_optimizer.step()\n",
    "    critic_optimizer.step()\n",
    "    \n",
    "    return policy_loss.item(), value_loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Episode:   10 | Mean Rewards: -200.00 |\n",
      "| Episode:   20 | Mean Rewards: -200.00 |\n",
      "| Episode:   30 | Mean Rewards: -200.00 |\n",
      "| Episode:   40 | Mean Rewards: -200.00 |\n",
      "| Episode:   50 | Mean Rewards: -200.00 |\n",
      "| Episode:   60 | Mean Rewards: -200.00 |\n",
      "| Episode:   70 | Mean Rewards: -200.00 |\n",
      "| Episode:   80 | Mean Rewards: -200.00 |\n",
      "| Episode:   90 | Mean Rewards: -200.00 |\n",
      "| Episode:  100 | Mean Rewards: -200.00 |\n",
      "| Episode:  110 | Mean Rewards: -200.00 |\n",
      "| Episode:  120 | Mean Rewards: -200.00 |\n",
      "| Episode:  130 | Mean Rewards: -200.00 |\n",
      "| Episode:  140 | Mean Rewards: -200.00 |\n",
      "| Episode:  150 | Mean Rewards: -200.00 |\n",
      "| Episode:  160 | Mean Rewards: -200.00 |\n",
      "| Episode:  170 | Mean Rewards: -200.00 |\n",
      "| Episode:  180 | Mean Rewards: -200.00 |\n",
      "| Episode:  190 | Mean Rewards: -200.00 |\n",
      "| Episode:  200 | Mean Rewards: -200.00 |\n",
      "| Episode:  210 | Mean Rewards: -200.00 |\n",
      "| Episode:  220 | Mean Rewards: -200.00 |\n",
      "| Episode:  230 | Mean Rewards: -200.00 |\n",
      "| Episode:  240 | Mean Rewards: -200.00 |\n",
      "| Episode:  250 | Mean Rewards: -200.00 |\n",
      "| Episode:  260 | Mean Rewards: -200.00 |\n",
      "| Episode:  270 | Mean Rewards: -200.00 |\n",
      "| Episode:  280 | Mean Rewards: -200.00 |\n",
      "| Episode:  290 | Mean Rewards: -200.00 |\n",
      "| Episode:  300 | Mean Rewards: -200.00 |\n",
      "| Episode:  310 | Mean Rewards: -200.00 |\n",
      "| Episode:  320 | Mean Rewards: -200.00 |\n",
      "| Episode:  330 | Mean Rewards: -200.00 |\n",
      "| Episode:  340 | Mean Rewards: -200.00 |\n",
      "| Episode:  350 | Mean Rewards: -200.00 |\n",
      "| Episode:  360 | Mean Rewards: -200.00 |\n",
      "| Episode:  370 | Mean Rewards: -200.00 |\n",
      "| Episode:  380 | Mean Rewards: -200.00 |\n",
      "| Episode:  390 | Mean Rewards: -200.00 |\n",
      "| Episode:  400 | Mean Rewards: -200.00 |\n",
      "| Episode:  410 | Mean Rewards: -200.00 |\n",
      "| Episode:  420 | Mean Rewards: -200.00 |\n",
      "| Episode:  430 | Mean Rewards: -200.00 |\n",
      "| Episode:  440 | Mean Rewards: -200.00 |\n",
      "| Episode:  450 | Mean Rewards: -200.00 |\n",
      "| Episode:  460 | Mean Rewards: -200.00 |\n",
      "| Episode:  470 | Mean Rewards: -200.00 |\n",
      "| Episode:  480 | Mean Rewards: -200.00 |\n",
      "| Episode:  490 | Mean Rewards: -200.00 |\n",
      "| Episode:  500 | Mean Rewards: -200.00 |\n"
     ]
    }
   ],
   "source": [
    "MAX_EPISODES = 500\n",
    "DISCOUNT_FACTOR = 0.99\n",
    "TRACE_DECAY = 0.97\n",
    "N_TRIALS = 25\n",
    "REWARD_THRESHOLD = 475\n",
    "PRINT_EVERY = 10\n",
    "\n",
    "episode_rewards = []\n",
    "\n",
    "for episode in range(1, MAX_EPISODES+1):\n",
    "    \n",
    "    policy_loss, value_loss, episode_reward = train(env, actor, critic, actor_optimizer, critic_optimizer, DISCOUNT_FACTOR, TRACE_DECAY)\n",
    "    \n",
    "    episode_rewards.append(episode_reward)\n",
    "    \n",
    "    mean_trial_rewards = np.mean(episode_rewards[-N_TRIALS:])\n",
    "    \n",
    "    if episode % PRINT_EVERY == 0:\n",
    "    \n",
    "        print(f'| Episode: {episode:4} | Mean Rewards: {mean_trial_rewards:6.2f} |')\n",
    "    \n",
    "    if mean_trial_rewards >= REWARD_THRESHOLD:\n",
    "        \n",
    "        print(f'Reached reward threshold in {episode} episodes')\n",
    "        \n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(episode_rewards)\n",
    "plt.xlabel('Episode', fontsize=20)\n",
    "plt.ylabel('Reward', fontsize=20)\n",
    "plt.hlines(REWARD_THRESHOLD, 0, len(episode_rewards), color='r')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
